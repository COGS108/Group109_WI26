{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your team list and their contributions. Note that this will change over the course of the checkpoints\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "- Emilia Vidrenko: Conceptualization, Data analysis, Methodology, Writing-original draft, Project administration and Team Expectations.\n",
    "- Chidiebere Agunanne: Data Cleaning, Research Question Hypothesis\n",
    "- Charlie Chang: Project administration, Software, Writing - review & editing\n",
    "- Dani Delgado: Analysis, Background research, Visualization, Writing - original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n",
    " -->\n",
    "How has the distribution of ICE arrests by country of citizenship changed across 2023, 2024, and 2025, and are certain countries consistently over- or underrepresented relative to their share of total arrests?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n",
    "\n",
    "**From Chidiebere- can you include that we are measuring ice enforcement in arrests,detentions, and deportations\n",
    "And the masurement we are using is the is the total number of outcomes per population i.e. the total number of people form country A that were either deported,arrested,or detained,/total number of ice cases** -->\n",
    "\n",
    "ICE is the U.S. Immigration and Customs Enforcement, or an agency within the Department of Homeland Security responsible for deportation and investigations regarding immigration law violations. After 9/11, the Homeland Security Act of 2002 was established. This act was established to reduce threats by terrorist networks and enforce immigration laws. In the following year, 2003, ICE was created under the Department of Homeland Security. Although ICE was created to enforce immigration laws, it has become very controversial in recent years, as some claim ICE has allegedly over-discriminated certain racial groups.\n",
    "\n",
    "Previously, work regarding our research question has been done and public data sets exist that compile ICE arrest and deportation records.<a href=\"#ref1\">1</a> This dataset shows information, including race, on many people ICE has encountered, arrested, detained, transported, deported, and jailed. However, this dataset lacks information about the total amount of immigrants from each country, and just gives raw data about the amount of immigrants that were arrested, etc. from a given country. There has also been research done regarding ICE arrest statistics in major US cities and their different types of arrests. <a href=\"#ref2\">2</a> This source has data on the arrest date, arrest city, country of citizenship, and criminality. However, a drawback to this source is the lack of accessibility of more specific data. There is only broad statistics having to do with ICE arrests in major cities. Furthermore, there is information about individual encounters with ICE enforcement in the final source. <a href=\"#ref3\">3</a> This source gives much more individual detail than the other sources, but still is lacking in terms of real-time updates.\n",
    "\n",
    "Through analyzing data from these three sources, we can begin to answer how the distribution of ICE arrests by country of citizenship has shifted across 2023, 2024, and 2025, and whether certain countries have become more or less overrepresented over time. Specifically, our group is measuring arrests done by ICE per country of origin of immigrants in the United States. This will be represented by the number of immigrants from a given country that have been arrested divided by the total number of ICE cases in the from the respective year 2023, 2024 and 2025.\n",
    "\n",
    "<a name=\"ref1\"></a>\n",
    "**1.** ICE Arrests, Detention, and Deportation Data (Kaggle).  \n",
    "https://www.kaggle.com/datasets/bwandowando/ice-arrests-detention-and-deportation-data/data  \n",
    "[↩](#ref1)\n",
    "\n",
    "<a name=\"ref2\"></a>\n",
    "**2**. U.S. Immigration and Customs Enforcement. Immigration Enforcement Statistics.  \n",
    "https://www.ice.gov/statistics  \n",
    "[↩](#ref2)\n",
    "\n",
    "<a name=\"ref3\"></a>\n",
    "**3**. Deportation Data Project. DeportationData.org.  \n",
    "https://deportationdata.org/index.html  \n",
    "[↩](#ref3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that the distribution of ICE arrests by country of citizenship will shift noticeably from 2023 to 2025, with some countries making up a growing share of total arrests while others decline. Specifically we expect individuals from Latin American countries to remain consistently overrepresented across all three years, largely due to longstanding enforcement patterns that have historically targeted populations perceived as more likely to lack legal documentation. Furthermore, we expect this overrepresentation to grow over time, driven by the increasing aggressiveness of ICE enforcement in recent years."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "<!-- Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets. -->\n",
    "\n",
    "- Dataset #1\n",
    "  - ice_arrests_2023_2025.csv\n",
    "  - https://docs.google.com/spreadsheets/d/1cqg27xsYpE_Jb5UxPetbhs0oWp1sotqrwln-ByW__Ks/export?format=csv&gid=476095224\n",
    "  - 500 Observations\n",
    "  - 23 Variables\n",
    "  - The relevant variables in this dataset include:\n",
    "    - apprehension_date - This states the date the person was arrested.\n",
    "    - citizenship_country - This states the country of citizenship of the person arrested.\n",
    "    - unique_identifier - This is an identifier unique to this person.\n",
    "  - The shortcomings of this dataset include the limited time frame from 2023-2025. This limited time frame only gives part of the picture, as data from before 2023 is unavailable. \n",
    "- Dataset #2\n",
    "  - ice_removals_2011_2023.csv\n",
    "  - https://docs.google.com/spreadsheets/d/1NKVmsceNFCyc3zSGiAhPxky-ASkx1KCiH0_63FuLInA/export?format=csv&gid=347174332\n",
    "  - 500 Observations\n",
    "  - 29 Variables\n",
    "  - The relevant variables in this dataset include:\n",
    "    - apprehension_date - This states the date the person was arrested.\n",
    "    - citizenship_country - This states the country of citizenship of the person arrested.\n",
    "    - unique_identifier - This is an identifier unique to this person.\n",
    "  - The shortcomings of this dataset include the limited time frame from 2011-2023. This limited time frame only gives part of the picture, as data from after 2023 is unavailable.\n",
    "\n",
    "We plan to combine these datasets. We plan to do this through adding all of the values from the ice_removals_2011_2023 to the ice_arrests_2023_2025. After we add these values, we will have information from between 2011-2025 available in one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Downloading ice_arrests_2023_2025.csv: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Overall Download Progress:  50%|█████     | 1/2 [00:00<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: ice_arrests_2023_2025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading ice_removals_2011_2023.csv: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: ice_removals_2011_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://docs.google.com/spreadsheets/d/1cqg27xsYpE_Jb5UxPetbhs0oWp1sotqrwln-ByW__Ks/export?format=csv&gid=476095224', 'filename':'ice_arrests_2023_2025.csv'},\n",
    "    { 'url': 'https://docs.google.com/spreadsheets/d/1NKVmsceNFCyc3zSGiAhPxky-ASkx1KCiH0_63FuLInA/export?format=csv&gid=347174332', 'filename':'ice_removals_2011_2023.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidying Data\n",
    "\n",
    "Tidying Data\n",
    "As you can see the above table belows is aleady tidy, each row is representing an individual observation and it is rectangular such that each variable measured is in a single column. You can also check this through the tidyness check below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apprehension_date</th>\n",
       "      <th>apprehension_state</th>\n",
       "      <th>apprehension_aor</th>\n",
       "      <th>final_program</th>\n",
       "      <th>final_program_group</th>\n",
       "      <th>apprehension_method</th>\n",
       "      <th>apprehension_criminality</th>\n",
       "      <th>case_status</th>\n",
       "      <th>case_category</th>\n",
       "      <th>departed_date</th>\n",
       "      <th>...</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>gender</th>\n",
       "      <th>apprehension_site_landmark</th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>apprehension_date_time</th>\n",
       "      <th>duplicate_likely</th>\n",
       "      <th>file_original</th>\n",
       "      <th>sheet_original</th>\n",
       "      <th>row_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston Area of Responsibility</td>\n",
       "      <td>Law Enforcement Area Response Units</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1976</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/1/2023 18:53:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston Area of Responsibility</td>\n",
       "      <td>Law Enforcement Area Response Units</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1979</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/1/2023 18:53:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Paso Area of Responsibility</td>\n",
       "      <td>Non-Detained Docket Control</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1985</td>\n",
       "      <td>HAITI</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/1/2023 22:13:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Paso Area of Responsibility</td>\n",
       "      <td>Non-Detained Docket Control</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1985</td>\n",
       "      <td>HAITI</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/1/2023 22:51:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/2/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston Area of Responsibility</td>\n",
       "      <td>Law Enforcement Area Response Units</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>PERU</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/2/2023 14:40:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  apprehension_date apprehension_state                apprehension_aor  \\\n",
       "0          9/1/2023                NaN   Boston Area of Responsibility   \n",
       "1          9/1/2023                NaN   Boston Area of Responsibility   \n",
       "2          9/1/2023                NaN  El Paso Area of Responsibility   \n",
       "3          9/1/2023                NaN  El Paso Area of Responsibility   \n",
       "4          9/2/2023                NaN   Boston Area of Responsibility   \n",
       "\n",
       "                         final_program final_program_group  \\\n",
       "0  Law Enforcement Area Response Units                 ICE   \n",
       "1  Law Enforcement Area Response Units                 ICE   \n",
       "2          Non-Detained Docket Control                 ICE   \n",
       "3          Non-Detained Docket Control                 ICE   \n",
       "4  Law Enforcement Area Response Units                 ICE   \n",
       "\n",
       "  apprehension_method      apprehension_criminality  case_status  \\\n",
       "0         Inspections  3 Other Immigration Violator          NaN   \n",
       "1         Inspections  3 Other Immigration Violator          NaN   \n",
       "2         Inspections  3 Other Immigration Violator          NaN   \n",
       "3         Inspections  3 Other Immigration Violator          NaN   \n",
       "4         Inspections  3 Other Immigration Violator          NaN   \n",
       "\n",
       "   case_category  departed_date  ...  birth_year  citizenship_country  gender  \\\n",
       "0            NaN            NaN  ...        1976             COLOMBIA  Female   \n",
       "1            NaN            NaN  ...        1979             COLOMBIA    Male   \n",
       "2            NaN            NaN  ...        1985                HAITI    Male   \n",
       "3            NaN            NaN  ...        1985                HAITI    Male   \n",
       "4            NaN            NaN  ...        2008                 PERU  Female   \n",
       "\n",
       "   apprehension_site_landmark unique_identifier apprehension_date_time  \\\n",
       "0                         NaN               NaN      9/1/2023 18:53:32   \n",
       "1                         NaN               NaN      9/1/2023 18:53:34   \n",
       "2                         NaN               NaN      9/1/2023 22:13:54   \n",
       "3                         NaN               NaN      9/1/2023 22:51:03   \n",
       "4                         NaN               NaN      9/2/2023 14:40:53   \n",
       "\n",
       "   duplicate_likely                                      file_original  \\\n",
       "0               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "1               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "2               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "3               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "4               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "\n",
       "  sheet_original  row_original  \n",
       "0  Admin Arrests        371689  \n",
       "1  Admin Arrests        371690  \n",
       "2  Admin Arrests        371691  \n",
       "3  Admin Arrests        371692  \n",
       "4  Admin Arrests        371695  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "import pandas as pd\n",
    "ice_arrests_2023_2025 = pd.read_csv(\"data/00-raw/ice_arrests_2023_2025.csv\")\n",
    "ice_arrests_2023_2025.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tidy data check:\n",
      "- Rows: 500 (each = one observation)\n",
      "- Columns: 23 (each = one variable: ['apprehension_date', 'apprehension_state', 'apprehension_aor', 'final_program', 'final_program_group', 'apprehension_method', 'apprehension_criminality', 'case_status', 'case_category', 'departed_date', 'departure_country', 'final_order_yes_no', 'final_order_date', 'birth_year', 'citizenship_country', 'gender', 'apprehension_site_landmark', 'unique_identifier', 'apprehension_date_time', 'duplicate_likely', 'file_original', 'sheet_original', 'row_original'])\n",
      "- No embedded multiple values per cell: True\n",
      "- Size: (500, 23)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"\"\"\n",
    "Tidy data check:\n",
    "- Rows: {len(ice_arrests_2023_2025)} (each = one observation)\n",
    "- Columns: {ice_arrests_2023_2025.shape[1]} (each = one variable: {ice_arrests_2023_2025.columns.tolist()})\n",
    "- No embedded multiple values per cell: {ice_arrests_2023_2025.apply(lambda col: col.astype(str).str.contains(',|;|/').any()).any()}\n",
    "- Size: {ice_arrests_2023_2025.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The series below shows how many values are missing and which columns they come from, totaling 140,960 missing values across the dataset. The missing data isn't random , it follows clear patterns that reflect what actually happened in each case. For example, departure information is blank for people who never departed, and case outcome fields are blank for cases that never made it to that stage in the process. In other words, the gaps in the data tell us something meaningful about the cases themselves rather than just being accidents or errors. Because of this, simply filling in the missing values would not be appropriate without a deeper understanding of what each gap actually represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apprehension_date               0\n",
       "apprehension_state            499\n",
       "apprehension_aor                7\n",
       "final_program                   0\n",
       "final_program_group             0\n",
       "apprehension_method             0\n",
       "apprehension_criminality        0\n",
       "case_status                   500\n",
       "case_category                 500\n",
       "departed_date                 500\n",
       "departure_country             500\n",
       "final_order_yes_no            500\n",
       "final_order_date              500\n",
       "birth_year                      0\n",
       "citizenship_country             0\n",
       "gender                          0\n",
       "apprehension_site_landmark    500\n",
       "unique_identifier             234\n",
       "apprehension_date_time          0\n",
       "duplicate_likely              234\n",
       "file_original                   0\n",
       "sheet_original                  0\n",
       "row_original                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_arrests_2023_2025.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our analysis focuses on apprehension_date, citizenship_country, and unique_identifier, outlier detection was scoped to only these columns. From the missingness analysis we already know that citizenship_country has just one missing value (negligible at this scale) and apprehension_date has no missing values. However, when converting apprehension_date to datetime a parse error surfaced at 1 row that raw null counts wouldn't catch. Inspecting both issues together confirmed they occur on the same row, meaning a single record accounts for all data quality concerns across these three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing citizenship_country:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apprehension_date</th>\n",
       "      <th>apprehension_state</th>\n",
       "      <th>apprehension_aor</th>\n",
       "      <th>final_program</th>\n",
       "      <th>final_program_group</th>\n",
       "      <th>apprehension_method</th>\n",
       "      <th>apprehension_criminality</th>\n",
       "      <th>case_status</th>\n",
       "      <th>case_category</th>\n",
       "      <th>departed_date</th>\n",
       "      <th>...</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>gender</th>\n",
       "      <th>apprehension_site_landmark</th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>apprehension_date_time</th>\n",
       "      <th>duplicate_likely</th>\n",
       "      <th>file_original</th>\n",
       "      <th>sheet_original</th>\n",
       "      <th>row_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [apprehension_date, apprehension_state, apprehension_aor, final_program, final_program_group, apprehension_method, apprehension_criminality, case_status, case_category, departed_date, departure_country, final_order_yes_no, final_order_date, birth_year, citizenship_country, gender, apprehension_site_landmark, unique_identifier, apprehension_date_time, duplicate_likely, file_original, sheet_original, row_original]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# citizenship_country has only 1 missing value — negligible\n",
    "print(\"Missing citizenship_country:\")\n",
    "ice_arrests_2023_2025[ice_arrests_2023_2025['citizenship_country'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apprehension_date</th>\n",
       "      <th>apprehension_state</th>\n",
       "      <th>apprehension_aor</th>\n",
       "      <th>final_program</th>\n",
       "      <th>final_program_group</th>\n",
       "      <th>apprehension_method</th>\n",
       "      <th>apprehension_criminality</th>\n",
       "      <th>case_status</th>\n",
       "      <th>case_category</th>\n",
       "      <th>departed_date</th>\n",
       "      <th>...</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>gender</th>\n",
       "      <th>apprehension_site_landmark</th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>apprehension_date_time</th>\n",
       "      <th>duplicate_likely</th>\n",
       "      <th>file_original</th>\n",
       "      <th>sheet_original</th>\n",
       "      <th>row_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [apprehension_date, apprehension_state, apprehension_aor, final_program, final_program_group, apprehension_method, apprehension_criminality, case_status, case_category, departed_date, departure_country, final_order_yes_no, final_order_date, birth_year, citizenship_country, gender, apprehension_site_landmark, unique_identifier, apprehension_date_time, duplicate_likely, file_original, sheet_original, row_original]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malformed_dates = pd.to_datetime(ice_arrests_2023_2025['apprehension_date'], errors='coerce').isnull()\n",
    "ice_arrests_2023_2025[malformed_dates]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Data\n",
    "To address missingness, we narrowed the dataset to the three columns relevant to our research question: apprehension_date, citizenship_country, and unique_identifier. Columns related to case outcomes, departure, and geographic processing were excluded entirely since our analysis only measures arrest counts by country and year. Rows missing a unique_identifier were dropped entirely, as they could not be reliably distinguished from one another across the two datasets, retaining them risked either double-counting or incorrectly matching unrelated records when merging. The single row missing citizenship_country was also dropped, leaving a clean dataset of uniquely identifiable arrest records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apprehension_date</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>unique_identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9/3/2023</td>\n",
       "      <td>UKRAINE</td>\n",
       "      <td>fa5080a66a9154f6cdf85f3dba8c9addfb14f9df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9/3/2023</td>\n",
       "      <td>UKRAINE</td>\n",
       "      <td>9a0ee8a71e894b948ec075653755cf8da81ba203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9/3/2023</td>\n",
       "      <td>UKRAINE</td>\n",
       "      <td>190173c71a1d654b85f858295de20be9cf90faa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9/3/2023</td>\n",
       "      <td>UKRAINE</td>\n",
       "      <td>0557755040334240981779d0d6fe5e3a1ac0ca40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9/5/2023</td>\n",
       "      <td>HONDURAS</td>\n",
       "      <td>b1e5fba0d3fc6bc16070305ceef8e5944926b595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1/15/2024</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>c65dba14c3b3adeaf528f671e5a8c55ad66ce5df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1/15/2024</td>\n",
       "      <td>UKRAINE</td>\n",
       "      <td>1fe843b7fd77613d9af336e1e1f7ec0f6e168f97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1/15/2024</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>d760470174684820fb7d98afcb632b57eb6bca6f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1/16/2024</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>c576002685e70f3eee7cba69018e9d2fe06a232b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1/16/2024</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>9096dedc24c8d4f4dbc23d11fb4056d92be667f5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    apprehension_date citizenship_country  \\\n",
       "8            9/3/2023             UKRAINE   \n",
       "9            9/3/2023             UKRAINE   \n",
       "10           9/3/2023             UKRAINE   \n",
       "11           9/3/2023             UKRAINE   \n",
       "13           9/5/2023            HONDURAS   \n",
       "..                ...                 ...   \n",
       "490         1/15/2024               SPAIN   \n",
       "491         1/15/2024             UKRAINE   \n",
       "494         1/15/2024              MEXICO   \n",
       "496         1/16/2024              MEXICO   \n",
       "497         1/16/2024              MEXICO   \n",
       "\n",
       "                            unique_identifier  \n",
       "8    fa5080a66a9154f6cdf85f3dba8c9addfb14f9df  \n",
       "9    9a0ee8a71e894b948ec075653755cf8da81ba203  \n",
       "10   190173c71a1d654b85f858295de20be9cf90faa1  \n",
       "11   0557755040334240981779d0d6fe5e3a1ac0ca40  \n",
       "13   b1e5fba0d3fc6bc16070305ceef8e5944926b595  \n",
       "..                                        ...  \n",
       "490  c65dba14c3b3adeaf528f671e5a8c55ad66ce5df  \n",
       "491  1fe843b7fd77613d9af336e1e1f7ec0f6e168f97  \n",
       "494  d760470174684820fb7d98afcb632b57eb6bca6f  \n",
       "496  c576002685e70f3eee7cba69018e9d2fe06a232b  \n",
       "497  9096dedc24c8d4f4dbc23d11fb4056d92be667f5  \n",
       "\n",
       "[266 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_arrests_2023_2025_clean = ice_arrests_2023_2025[['apprehension_date', 'citizenship_country', 'unique_identifier']]\n",
    "ice_arrests_2023_2025_clean = ice_arrests_2023_2025_clean.dropna(subset=['citizenship_country','unique_identifier'])\n",
    "ice_arrests_2023_2025_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 U.S. ICE 2011–2023 Historical Removals Data\n",
    "\n",
    "<!-- See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the above table below is already tidy, each row is representing an individual observation and it is rectangular such that each variable measured is in a single column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2A: Data Description and Core Variables \n",
    "\n",
    "This dataset contains individual-level ICE removal records spanning 2011 through 2023. Each row represents a single removal case, and each column corresponds to an administrative attribute of that enforcement action. For the purposes of our analysis, we focus specifically on two core variables: Apprehension Date and Country of Citizenship, which allow us to construct annual distributions of removals by nationality.\n",
    "\n",
    "Key Metrics:\n",
    "\n",
    "1. Apprehension Date (date/timestamp format):\n",
    "This variable records the date on which the enforcement action was recorded. The unit of measurement is calendar time at the day level. For analytical purposes, we extract the year from this variable to aggregate removals by calendar year and enable longitudinal comparisons across 2011–2023.\n",
    "\n",
    "2. Country of Citizenship (categorical variable):\n",
    "This variable identifies the nationality of the individual removed. It is central to our research question, as we calculate the proportion of total removals attributable to each country in a given year.\n",
    "\n",
    "3. Arrest Count (derived metric):\n",
    "Although the dataset does not directly report overall totals, each row represents a single removal case. Therefore, counting the number of rows gives the total number of removals. We can group these rows (for example, by year or country) to calculate counts and then convert those counts into proportions, such as each country’s share of total annual removals. Furthermore, although the dataset is structured around removals, the inclusion of the Apprehension Date column allows us to focus on the timing of apprehensions and treat each row as representing a single arrest case. In this way, we can similarly compute totals and proportions for arrests by year or country.\n",
    "\n",
    "Primary Outcome of Interest: is the proportional composition of arrests by country within each year.\n",
    "\n",
    "Because overall enforcement volume fluctuates across years, we focus on proportions rather than raw counts. For example, if 30% of removals in a given year involve individuals from a specific country, this indicates that nearly one-third of arrests that year were associated with that nationality. This proportional approach allows us to compare enforcement composition over time even when total arrests increase or decrease.\n",
    "\n",
    "2B: Data Limitations and Methodological Considerations\n",
    "\n",
    "1. Policy-driven variation:\n",
    "ICE enforcement priorities shifted across administrations between 2011 and 2023. As a result, observed changes in arrest proportions may reflect policy changes rather than underlying migration flows.\n",
    "\n",
    "2. Administrative data bias:\n",
    "This dataset captures enforcement outcomes, not the total undocumented population. It measures government enforcement activity rather than population-level prevalence.\n",
    "\n",
    "3. Missing administrative identifiers:\n",
    "Some internal identifiers contain missing values. However, because our analysis depends primarily on apprehension date and country of citizenship, this missingness does not materially affect our proportional calculations.\n",
    "\n",
    "4. Scope limitation:\n",
    "The dataset includes only individuals who were formally removed. It excludes those apprehended but released, voluntarily departed, or never encountered by enforcement authorities. Therefore, the data reflect enforcement outcomes rather than the broader undocumented population. Findings should be interpreted as changes in enforcement composition rather than changes in total immigrant presence.\n",
    "\n",
    "Relationship to Dataset #1\n",
    "\n",
    "Dataset #2 provides the historical baseline (2011–2023), while Dataset #1 extends the timeline into 2023–2025. To construct a continuous time series, we harmonize the shared variables (apprehension date and country of citizenship) and append the relevant 2023 records from Dataset #2 to Dataset #1. This produces a unified dataset spanning 2011–2025 for proportional analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the above table belows is aleady tidy, each row is representing an individual observation and it is rectangular such that each variable measured is in a single column. You can allso check this trhough the tidyness check below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Departure Date</th>\n",
       "      <th>Port of Departure</th>\n",
       "      <th>Departure Country</th>\n",
       "      <th>Case Status</th>\n",
       "      <th>Case Category</th>\n",
       "      <th>Final Order Yes No</th>\n",
       "      <th>Final Order Date</th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Birth Country</th>\n",
       "      <th>...</th>\n",
       "      <th>MSC Conviction Date</th>\n",
       "      <th>MSC Criminal Charge Status</th>\n",
       "      <th>Case Threat Level</th>\n",
       "      <th>Processing Disposition Code</th>\n",
       "      <th>Processing Disposition</th>\n",
       "      <th>Current Program</th>\n",
       "      <th>Apprehension Date</th>\n",
       "      <th>Charge Section Code</th>\n",
       "      <th>Charge Code</th>\n",
       "      <th>Anonymized Identifer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/28/2023</td>\n",
       "      <td>EAGLE PASS, TX, INTL BRIDGE #2, POE</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>8-Excluded/Removed - Inadmissibility</td>\n",
       "      <td>[16] Reinstated Final Order</td>\n",
       "      <td>True</td>\n",
       "      <td>10/27/2023</td>\n",
       "      <td>(b)(6)(b)(7)(c)(b)(7)(e)</td>\n",
       "      <td>Male</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REINST</td>\n",
       "      <td>REINSTATEMENT OF DEPORT ORDER I-871</td>\n",
       "      <td>Border Patrol</td>\n",
       "      <td>10/27/2023 16:54:14</td>\n",
       "      <td>212a9Aii</td>\n",
       "      <td>I9A2</td>\n",
       "      <td>92350d4cc5510c97f2ede81696c56fc2ffaf267b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/21/2021</td>\n",
       "      <td>PASO DEL NORTE, TX, POE</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>6-Deported/Removed - Deportability</td>\n",
       "      <td>[16] Reinstated Final Order</td>\n",
       "      <td>True</td>\n",
       "      <td>4/30/2018</td>\n",
       "      <td>(b)(6)(b)(7)(c)(b)(7)(e)</td>\n",
       "      <td>Female</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>...</td>\n",
       "      <td>10/9/2019</td>\n",
       "      <td>Convicted</td>\n",
       "      <td>3.0</td>\n",
       "      <td>REINST</td>\n",
       "      <td>REINSTATEMENT OF DEPORT ORDER I-871</td>\n",
       "      <td>Border Patrol</td>\n",
       "      <td>10/21/2023 12:38:08</td>\n",
       "      <td>212a9Aii</td>\n",
       "      <td>I9A2</td>\n",
       "      <td>a46c144a9ebbe8f9f7e3bdbec14adaabe3001b99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/18/2023</td>\n",
       "      <td>HARLINGEN, TX, POE</td>\n",
       "      <td>GUATEMALA</td>\n",
       "      <td>8-Excluded/Removed - Inadmissibility</td>\n",
       "      <td>[16] Reinstated Final Order</td>\n",
       "      <td>True</td>\n",
       "      <td>8/10/2023</td>\n",
       "      <td>(b)(6)(b)(7)(c)(b)(7)(e)</td>\n",
       "      <td>Male</td>\n",
       "      <td>GUATEMALA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REINST</td>\n",
       "      <td>REINSTATEMENT OF DEPORT ORDER I-871</td>\n",
       "      <td>Border Patrol</td>\n",
       "      <td>10/17/2023 20:03:32</td>\n",
       "      <td>212a9Aii</td>\n",
       "      <td>I9A2</td>\n",
       "      <td>b16fc03e7f7ca06da1cea2095d0ca4357d5f7988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/15/2023</td>\n",
       "      <td>PASO DEL NORTE, TX, POE</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>6-Deported/Removed - Deportability</td>\n",
       "      <td>[16] Reinstated Final Order</td>\n",
       "      <td>True</td>\n",
       "      <td>8/14/2015</td>\n",
       "      <td>(b)(6)(b)(7)(c)(b)(7)(e)</td>\n",
       "      <td>Female</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REINST</td>\n",
       "      <td>REINSTATEMENT OF DEPORT ORDER I-871</td>\n",
       "      <td>Border Patrol</td>\n",
       "      <td>10/15/2023 4:18:00</td>\n",
       "      <td>212a9Aii</td>\n",
       "      <td>I9A2</td>\n",
       "      <td>9c7d5463fa392e912e01e640d7eff816ffd69ef2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/23/2023</td>\n",
       "      <td>HARLINGEN, TX, POE</td>\n",
       "      <td>HONDURAS</td>\n",
       "      <td>8-Excluded/Removed - Inadmissibility</td>\n",
       "      <td>[8F] Expedited Removal</td>\n",
       "      <td>True</td>\n",
       "      <td>10/12/2023</td>\n",
       "      <td>(b)(6)(b)(7)(c)(b)(7)(e)</td>\n",
       "      <td>Male</td>\n",
       "      <td>HONDURAS</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ER</td>\n",
       "      <td>Expedited Removal (I-860)</td>\n",
       "      <td>Border Patrol</td>\n",
       "      <td>10/12/2023 5:20:16</td>\n",
       "      <td>212a7AiI</td>\n",
       "      <td>I7A1</td>\n",
       "      <td>6d3621106ad7d5e83cebb941747870a9869963bc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Departure Date                    Port of Departure Departure Country  \\\n",
       "0      9/28/2023  EAGLE PASS, TX, INTL BRIDGE #2, POE            MEXICO   \n",
       "1     10/21/2021              PASO DEL NORTE, TX, POE            MEXICO   \n",
       "2      8/18/2023                   HARLINGEN, TX, POE         GUATEMALA   \n",
       "3      9/15/2023              PASO DEL NORTE, TX, POE            MEXICO   \n",
       "4      9/23/2023                   HARLINGEN, TX, POE          HONDURAS   \n",
       "\n",
       "                            Case Status                Case Category  \\\n",
       "0  8-Excluded/Removed - Inadmissibility  [16] Reinstated Final Order   \n",
       "1    6-Deported/Removed - Deportability  [16] Reinstated Final Order   \n",
       "2  8-Excluded/Removed - Inadmissibility  [16] Reinstated Final Order   \n",
       "3    6-Deported/Removed - Deportability  [16] Reinstated Final Order   \n",
       "4  8-Excluded/Removed - Inadmissibility       [8F] Expedited Removal   \n",
       "\n",
       "   Final Order Yes No Final Order Date                   Case ID  Gender  \\\n",
       "0                True       10/27/2023  (b)(6)(b)(7)(c)(b)(7)(e)    Male   \n",
       "1                True        4/30/2018  (b)(6)(b)(7)(c)(b)(7)(e)  Female   \n",
       "2                True        8/10/2023  (b)(6)(b)(7)(c)(b)(7)(e)    Male   \n",
       "3                True        8/14/2015  (b)(6)(b)(7)(c)(b)(7)(e)  Female   \n",
       "4                True       10/12/2023  (b)(6)(b)(7)(c)(b)(7)(e)    Male   \n",
       "\n",
       "  Birth Country  ... MSC Conviction Date  MSC Criminal Charge Status  \\\n",
       "0        MEXICO  ...                 NaN                         NaN   \n",
       "1        MEXICO  ...           10/9/2019                   Convicted   \n",
       "2     GUATEMALA  ...                 NaN                         NaN   \n",
       "3        MEXICO  ...                 NaN                         NaN   \n",
       "4      HONDURAS  ...                 NaN                         NaN   \n",
       "\n",
       "   Case Threat Level Processing Disposition Code  \\\n",
       "0                NaN                      REINST   \n",
       "1                3.0                      REINST   \n",
       "2                NaN                      REINST   \n",
       "3                NaN                      REINST   \n",
       "4                NaN                          ER   \n",
       "\n",
       "                Processing Disposition Current Program    Apprehension Date  \\\n",
       "0  REINSTATEMENT OF DEPORT ORDER I-871   Border Patrol  10/27/2023 16:54:14   \n",
       "1  REINSTATEMENT OF DEPORT ORDER I-871   Border Patrol  10/21/2023 12:38:08   \n",
       "2  REINSTATEMENT OF DEPORT ORDER I-871   Border Patrol  10/17/2023 20:03:32   \n",
       "3  REINSTATEMENT OF DEPORT ORDER I-871   Border Patrol   10/15/2023 4:18:00   \n",
       "4            Expedited Removal (I-860)   Border Patrol   10/12/2023 5:20:16   \n",
       "\n",
       "  Charge Section Code Charge Code                      Anonymized Identifer  \n",
       "0            212a9Aii        I9A2  92350d4cc5510c97f2ede81696c56fc2ffaf267b  \n",
       "1            212a9Aii        I9A2  a46c144a9ebbe8f9f7e3bdbec14adaabe3001b99  \n",
       "2            212a9Aii        I9A2  b16fc03e7f7ca06da1cea2095d0ca4357d5f7988  \n",
       "3            212a9Aii        I9A2  9c7d5463fa392e912e01e640d7eff816ffd69ef2  \n",
       "4            212a7AiI        I7A1  6d3621106ad7d5e83cebb941747870a9869963bc  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "ice_removals_2011_2023 = pd.read_csv(\"data/00-raw/ice_removals_2011_2023.csv\")\n",
    "ice_removals_2011_2023.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate that the data is tidy, we can inspect the unique values of some of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tidy data check:\n",
      "- Rows: 500 (each = one observation)\n",
      "- Columns: 29 (each = one variable: ['apprehension_date', 'apprehension_state', 'apprehension_aor', 'final_program', 'final_program_group', 'apprehension_method', 'apprehension_criminality', 'case_status', 'case_category', 'departed_date', 'departure_country', 'final_order_yes_no', 'final_order_date', 'birth_year', 'citizenship_country', 'gender', 'apprehension_site_landmark', 'unique_identifier', 'apprehension_date_time', 'duplicate_likely', 'file_original', 'sheet_original', 'row_original'])\n",
      "- No embedded multiple values per cell: True\n",
      "- Size: (500, 29)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Tidy data check:\n",
    "- Rows: {len(ice_removals_2011_2023)} (each = one observation)\n",
    "- Columns: {ice_removals_2011_2023.shape[1]} (each = one variable: {ice_arrests_2023_2025.columns.tolist()})\n",
    "- No embedded multiple values per cell: {ice_removals_2011_2023.apply(lambda col: col.astype(str).str.contains(',|;|/').any()).any()}\n",
    "- Size: {ice_removals_2011_2023.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows how many values are missing in the dataset, and from which columns, when totaled it comes out to 1650778.Missingness in this dataset is neither random nor uniform. It clusters into structured groups that reflect real-world case characteristics rather than data quality problems. The most striking pattern is the MSC criminal charge block, where MSC Charge, MSC Charge Code, MSC Conviction Date, MSC Criminal Charge Status, and Case Threat Level are all missing for roughly 153,800 records. These fields are absent because the individual has no criminal charge on record, making that it is missing not at random.Something similar explains why Birth Date is missing for over 437,000 records while Birth Year is almost fully complete. The system appears to have routinely recorded year of birth but not the full date, so this is a collection limitation rather than an error.Fields like Entry Date and Final Order Date are missing for a large chunk of records too, probably because those events never happened for those cases.A handful of fields like Alien File Number and Anonymized Identifier go missing together in the same rows, suggesting a specific batch of records was never fully processed. And a few fields are only missing once, which at this scale is negligible and is probably all the same row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Departure Date                   0\n",
       "Port of Departure                0\n",
       "Departure Country                0\n",
       "Case Status                      0\n",
       "Case Category                    0\n",
       "Final Order Yes No               0\n",
       "Final Order Date                43\n",
       "Case ID                          0\n",
       "Gender                           0\n",
       "Birth Country                    0\n",
       "Citizenship Country              0\n",
       "Birth Date                     500\n",
       "Birth Year                       0\n",
       "Alien File Number               16\n",
       "Entry Status                     1\n",
       "Entry Date                      46\n",
       "MSC Charge                     351\n",
       "MSC Charge Date                364\n",
       "MSC Charge Code                351\n",
       "MSC Conviction Date            351\n",
       "MSC Criminal Charge Status     351\n",
       "Case Threat Level              351\n",
       "Processing Disposition Code      0\n",
       "Processing Disposition           0\n",
       "Current Program                  0\n",
       "Apprehension Date                0\n",
       "Charge Section Code              0\n",
       "Charge Code                      0\n",
       "Anonymized Identifer            16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_removals_2011_2023.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our analysis focuses on Apprehension Date, Citizenship Country, and Anonymized Identifier, outlier detection was scoped to only these columns. Citizenship Country and Apprehension Date each have just one missing value (negligible at this scale). Anonymized Identifier had more substantial missingness, which prompted a duplicate check. This revealed 9 duplicate values in the dataset, all of which have been flagged since it is unclear whether they represent distinct individuals recorded twice or the same case entered multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Departure Date</th>\n",
       "      <th>Port of Departure</th>\n",
       "      <th>Departure Country</th>\n",
       "      <th>Case Status</th>\n",
       "      <th>Case Category</th>\n",
       "      <th>Final Order Yes No</th>\n",
       "      <th>Final Order Date</th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Birth Country</th>\n",
       "      <th>...</th>\n",
       "      <th>MSC Conviction Date</th>\n",
       "      <th>MSC Criminal Charge Status</th>\n",
       "      <th>Case Threat Level</th>\n",
       "      <th>Processing Disposition Code</th>\n",
       "      <th>Processing Disposition</th>\n",
       "      <th>Current Program</th>\n",
       "      <th>Apprehension Date</th>\n",
       "      <th>Charge Section Code</th>\n",
       "      <th>Charge Code</th>\n",
       "      <th>Anonymized Identifer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Departure Date, Port of Departure, Departure Country, Case Status, Case Category, Final Order Yes No, Final Order Date, Case ID, Gender, Birth Country, Citizenship Country, Birth Date, Birth Year, Alien File Number, Entry Status, Entry Date, MSC Charge, MSC Charge Date, MSC Charge Code, MSC Conviction Date, MSC Criminal Charge Status, Case Threat Level, Processing Disposition Code, Processing Disposition, Current Program, Apprehension Date, Charge Section Code, Charge Code, Anonymized Identifer]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malformed_dates = pd.to_datetime(ice_removals_2011_2023['Apprehension Date']).isnull()\n",
    "ice_removals_2011_2023[malformed_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Departure Date</th>\n",
       "      <th>Port of Departure</th>\n",
       "      <th>Departure Country</th>\n",
       "      <th>Case Status</th>\n",
       "      <th>Case Category</th>\n",
       "      <th>Final Order Yes No</th>\n",
       "      <th>Final Order Date</th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Birth Country</th>\n",
       "      <th>...</th>\n",
       "      <th>MSC Conviction Date</th>\n",
       "      <th>MSC Criminal Charge Status</th>\n",
       "      <th>Case Threat Level</th>\n",
       "      <th>Processing Disposition Code</th>\n",
       "      <th>Processing Disposition</th>\n",
       "      <th>Current Program</th>\n",
       "      <th>Apprehension Date</th>\n",
       "      <th>Charge Section Code</th>\n",
       "      <th>Charge Code</th>\n",
       "      <th>Anonymized Identifer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Departure Date, Port of Departure, Departure Country, Case Status, Case Category, Final Order Yes No, Final Order Date, Case ID, Gender, Birth Country, Citizenship Country, Birth Date, Birth Year, Alien File Number, Entry Status, Entry Date, MSC Charge, MSC Charge Date, MSC Charge Code, MSC Conviction Date, MSC Criminal Charge Status, Case Threat Level, Processing Disposition Code, Processing Disposition, Current Program, Apprehension Date, Charge Section Code, Charge Code, Anonymized Identifer]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Duplicated Values')\n",
    "ice_removals_2011_2023[ice_removals_2011_2023.duplicated(keep=False)].sort_values(by=ice_removals_2011_2023.columns.tolist()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address missingness, we narrowed the dataset to the three columns relevant to our research question: Apprehension Date, Citizenship Country, and Anonymized Identifier. Columns related to case outcomes, departure, and geographic processing were excluded entirely since our analysis only measures arrest counts by country and year. Rows missing an Anonymized Identifier were dropped entirely, as they could not be reliably distinguished from one another across the two datasets, retaining them risked either double-counting or incorrectly matching unrelated records when merging. The remaining duplicate rows identified during outlier detection were also dropped, keeping the first occurrence of each record to preserve arrest counts as accurately as possible. The single row missing Citizenship Country was also dropped, leaving a clean dataset of uniquely identifiable arrest records. Finally, Apprehension Date was converted to date-only format, dropping the time component, and all retained columns were renamed to match the conventions used in the first dataset, both steps taken to ensure consistency across the two sources before merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apprehension_date</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>unique_identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/27/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>92350d4cc5510c97f2ede81696c56fc2ffaf267b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/21/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>a46c144a9ebbe8f9f7e3bdbec14adaabe3001b99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/17/2023</td>\n",
       "      <td>GUATEMALA</td>\n",
       "      <td>b16fc03e7f7ca06da1cea2095d0ca4357d5f7988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/15/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>9c7d5463fa392e912e01e640d7eff816ffd69ef2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/12/2023</td>\n",
       "      <td>HONDURAS</td>\n",
       "      <td>6d3621106ad7d5e83cebb941747870a9869963bc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>2817bb792587669fc5af3007dd6dcae9229540a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>0b9fc9d7dbc18082e9b08c98ac8590389a25c756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>52beae0d76e16b4e9d137e1b3f0e7f9b77631b77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>31626f2a364ad9d66e9d6049e378604f03cb104e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>bc430eca6fb59facbf22fe29ca47da43287a2973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    apprehension_date citizenship_country  \\\n",
       "0          10/27/2023              MEXICO   \n",
       "1          10/21/2023              MEXICO   \n",
       "2          10/17/2023           GUATEMALA   \n",
       "3          10/15/2023              MEXICO   \n",
       "4          10/12/2023            HONDURAS   \n",
       "..                ...                 ...   \n",
       "495        09/25/2023              MEXICO   \n",
       "496        09/25/2023              MEXICO   \n",
       "497        09/25/2023              MEXICO   \n",
       "498        09/25/2023              MEXICO   \n",
       "499        09/25/2023              MEXICO   \n",
       "\n",
       "                            unique_identifier  \n",
       "0    92350d4cc5510c97f2ede81696c56fc2ffaf267b  \n",
       "1    a46c144a9ebbe8f9f7e3bdbec14adaabe3001b99  \n",
       "2    b16fc03e7f7ca06da1cea2095d0ca4357d5f7988  \n",
       "3    9c7d5463fa392e912e01e640d7eff816ffd69ef2  \n",
       "4    6d3621106ad7d5e83cebb941747870a9869963bc  \n",
       "..                                        ...  \n",
       "495  2817bb792587669fc5af3007dd6dcae9229540a3  \n",
       "496  0b9fc9d7dbc18082e9b08c98ac8590389a25c756  \n",
       "497  52beae0d76e16b4e9d137e1b3f0e7f9b77631b77  \n",
       "498  31626f2a364ad9d66e9d6049e378604f03cb104e  \n",
       "499  bc430eca6fb59facbf22fe29ca47da43287a2973  \n",
       "\n",
       "[484 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_removals_2011_2023_clean = ice_removals_2011_2023.drop_duplicates(keep='first')\n",
    "ice_removals_2011_2023_clean = ice_removals_2011_2023_clean.dropna(subset=['Citizenship Country','Anonymized Identifer'])\n",
    "ice_removals_2011_2023_clean = ice_removals_2011_2023_clean[['Apprehension Date','Citizenship Country','Anonymized Identifer']]\n",
    "ice_removals_2011_2023_clean['Apprehension Date'] = pd.to_datetime(ice_removals_2011_2023_clean['Apprehension Date']).dt.strftime('%#m/%#d/%Y')\n",
    "ice_removals_2011_2023_clean = ice_removals_2011_2023_clean.rename(columns={\n",
    "    'Apprehension Date': 'apprehension_date',\n",
    "    'Citizenship Country': 'citizenship_country',\n",
    "    'Anonymized Identifer': 'unique_identifier'\n",
    "})\n",
    "ice_removals_2011_2023_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Datasets\n",
    "\n",
    "As noted earlier, the ICE 2023–2025 Arrests Dataset only covers September 2023 through October 2025, meaning arrests that occurred before September 2023 are not captured. To ensure a more complete picture, we concatenated it with the ICE 2011–2023 Removals Dataset. After cleaning, both datasets share the same column names and structure, making pd.concat a straightforward way to combine all observations into a single unified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apprehension_date</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>unique_identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/3/2023</td>\n",
       "      <td>UKRAINE</td>\n",
       "      <td>fa5080a66a9154f6cdf85f3dba8c9addfb14f9df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/3/2023</td>\n",
       "      <td>UKRAINE</td>\n",
       "      <td>9a0ee8a71e894b948ec075653755cf8da81ba203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/3/2023</td>\n",
       "      <td>UKRAINE</td>\n",
       "      <td>190173c71a1d654b85f858295de20be9cf90faa1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/3/2023</td>\n",
       "      <td>UKRAINE</td>\n",
       "      <td>0557755040334240981779d0d6fe5e3a1ac0ca40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/5/2023</td>\n",
       "      <td>HONDURAS</td>\n",
       "      <td>b1e5fba0d3fc6bc16070305ceef8e5944926b595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>2817bb792587669fc5af3007dd6dcae9229540a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>0b9fc9d7dbc18082e9b08c98ac8590389a25c756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>52beae0d76e16b4e9d137e1b3f0e7f9b77631b77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>31626f2a364ad9d66e9d6049e378604f03cb104e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>09/25/2023</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>bc430eca6fb59facbf22fe29ca47da43287a2973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    apprehension_date citizenship_country  \\\n",
       "0            9/3/2023             UKRAINE   \n",
       "1            9/3/2023             UKRAINE   \n",
       "2            9/3/2023             UKRAINE   \n",
       "3            9/3/2023             UKRAINE   \n",
       "4            9/5/2023            HONDURAS   \n",
       "..                ...                 ...   \n",
       "745        09/25/2023              MEXICO   \n",
       "746        09/25/2023              MEXICO   \n",
       "747        09/25/2023              MEXICO   \n",
       "748        09/25/2023              MEXICO   \n",
       "749        09/25/2023              MEXICO   \n",
       "\n",
       "                            unique_identifier  \n",
       "0    fa5080a66a9154f6cdf85f3dba8c9addfb14f9df  \n",
       "1    9a0ee8a71e894b948ec075653755cf8da81ba203  \n",
       "2    190173c71a1d654b85f858295de20be9cf90faa1  \n",
       "3    0557755040334240981779d0d6fe5e3a1ac0ca40  \n",
       "4    b1e5fba0d3fc6bc16070305ceef8e5944926b595  \n",
       "..                                        ...  \n",
       "745  2817bb792587669fc5af3007dd6dcae9229540a3  \n",
       "746  0b9fc9d7dbc18082e9b08c98ac8590389a25c756  \n",
       "747  52beae0d76e16b4e9d137e1b3f0e7f9b77631b77  \n",
       "748  31626f2a364ad9d66e9d6049e378604f03cb104e  \n",
       "749  bc430eca6fb59facbf22fe29ca47da43287a2973  \n",
       "\n",
       "[750 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_arrests_2011_2025 = pd.concat([ice_arrests_2023_2025_clean, ice_removals_2011_2023_clean], ignore_index=True)\n",
    "ice_arrests_2011_2025"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent? --> crucial\n",
    "\n",
    ">  We have publicly administered data from ICE and Keggle websites, we are not collecting information for human subjects throughout our project. Our data consist of information we gather from enforcement statistics instead of individual participants. \n",
    " \n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> We have considered that the data we are using specifically from the ICE website would reflect what they specifically chose to focus on and on certain policies that have changed. We are aware that the data would be based on ICE enforcement instead of the people themselves.  \n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> Our data set does not include any names or personal information on individuals, we are not trying to figure out who they are. \n",
    "    \n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> We are aware that Immigration is a heavy topic especially in the state of the world we are in right now, we will be careful to present the results of our data in a respectful way that doesnt shift blame or target certain groups. Making sure we focus on certain enforcement patterns instead of the individuals. \n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> The data we are using is public and does not include any personal information of individuals. Our data would be safely secured in datahub and github for this project.\n",
    "       \n",
    " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "> We are using that dataset only for this project, once the project is over the data will stay in our data repository just for documentation. \n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> We are aware that the dataset shows government reported data and patterns, and will most likely not include personal experience or certain perspectives of the individuals.  \n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> The data we have considered that it might have missing data or uneven reportings across different countries, since the data reflects enforcement activity instead of certain behaviors conducted. We will avoid making causal claims and just observing the patterns we see within the data.  \n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> We will make sure to make graphs and summaries that accurately represent the data we used, avoiding any skewed data.\n",
    " \n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> We will ensure that we will not display or use any personal information for our analysis.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "> Our analysis and data will be well documented in order for others to understand our work and if they decide they would be able to reproduce it clearly. \n",
    "\n",
    "### D. Modeling\n",
    " - [ ] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "> Our data shows arrest, removals, etc. But it does not explain specific reasons behind these actions and we also don't know the experiences of the people affected by this. With that being said we will make sure to make that a point when presenting our results, making the limits clear. \n",
    "\n",
    "### E. Deployment\n",
    " - [ ] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [ ] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [ ] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "> We are aware that some of the data and findings that we use could be mistaken to support harmful narratives. So we will make it clear in our analysis to explain everything to reduce potential risks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our COGS 108 project examining whether ICE arrest activity has differed by country of citizenship over the last two years (2023 - 2025), we agree to work as a collaborative, respectful, and accountable team. Given the sensitivity of immigration-related data and the interdisciplinary nature of this topic, we recognize the importance of clear communication, shared responsibility, and mutual respect throughout the quarter.\n",
    "\n",
    "Communication \n",
    "We will primarily communicate through Messenger with the expectation that messages will be acknowledged within 24 hours. We will schedule weekly meetings (remote, as agreed upon) to review progress, assign tasks and discuss challenges. If a team member anticipates being unavailable or delayed, they will notify the group as soon as possible.\n",
    "\n",
    "Tone and Respect\n",
    "We commit to maintaining a professional, respectful, and constructive tone in all interactions. We agree to be honest and direct while remaining polite. Given that this project involves topics related to immigration and enforcement, we will be especially mindful to discuss findings analytically and respectfully, separating personal opinions from data-driven conclusions.\n",
    "\n",
    "Decision-Making\n",
    "Whenever possible, decisions will be made by consensus. If consensus cannot be reached in a reasonable timeframe, we will use a majority vote. For time-sensitive decisions (e.g., minor coding or formatting choices), the team member responsible for that section may proceed and update the group afterward.\n",
    "\n",
    "Task Distribution and Accountability\n",
    "Work will be divided equitably based on individual strengths (e.g., data wrangling, analysis, visualization, writing), while ensuring that every member contributes to all major aspects of the project: data selection, analysis, code development, interpretation, and writing. Tasks and deadlines will be tracked using a shared task board or document (e.g., GitHub Issues, Google Docs). No single team member is expected to carry a disproportionate share of the workload.\n",
    "\n",
    "Supporting One Another\n",
    "If a team member is struggling with an assigned task, they are expected to communicate this early so the team can redistribute work or provide support. We agree to approach these situations with understanding and problem-solving rather than blame.\n",
    "\n",
    "Conflict Resolution\n",
    "If conflicts arise, we will address them directly, respectfully, and privately as a group before escalating. We will assume good intentions and focus on resolving issues in a way that supports both the project’s success and the well-being of the team. If serious issues persist, we understand that reaching out to course staff is an appropriate step, in line with course policy.\n",
    "\n",
    "Commitment\n",
    "By adding our names to this submission, we confirm that we have read the COGS108 Team Policies, agree to the expectations outlined above, and are committed to contributing fully and responsibly to this project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/27  |  1 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/4  |  4 PM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/17  | 4 PM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/18  | 4 PM  | Import & Wrangle Data (Ant Man); EDA (Hulk) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 4 PM  | Finalize wrangling/EDA; Begin Analysis (Iron Man; Thor) | Discuss/edit Analysis; Complete project check-in |\n",
    "| 3/13  | 4 PM  | Complete analysis; Draft results/conclusion/discussion (Wasp)| Discuss/edit full project |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
