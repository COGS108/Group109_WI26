{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your team list and their contributions. Note that this will change over the course of the checkpoints\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "- Emilia Vidrenko: Conceptualization, Data analysis, Methodology, Writing-original draft, Project administration and Team Expectations.\n",
    "- Bob Barker:  Analysis, Software, Visualization\n",
    "- Charlie Chang: Project administration, Software, Writing - review & editing\n",
    "- Dani Delgado: Analysis, Background research, Visualization, Writing - original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n",
    " -->\n",
    "How has the distribution of ICE arrests by country of citizenship changed across 2023, 2024, and 2025, and are certain countries consistently over- or underrepresented relative to their share of total arrests?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Instructions: REPLACE the contents of this cell with your work, including any updates to recover points lost in your proposal feedback\n",
    "\n",
    "**From Chidiebere- can you include that we are measuring ice enforcement in arrests,detentions, and deportations\n",
    "And the masurement we are using is the is the total number of outcomes per population i.e. the total number of people form country A that were either deported,arrested,or detained,/total number of ice cases** -->\n",
    "\n",
    "ICE is the U.S. Immigration and Customs Enforcement, or an agency within the Department of Homeland Security responsible for deportation and investigations regarding immigration law violations. After 9/11, the Homeland Security Act of 2002 was established. This act was established to reduce threats by terrorist networks and enforce immigration laws. In the following year, 2003, ICE was created under the Department of Homeland Security. Although ICE was created to enforce immigration laws, it has become very controversial in recent years, as some claim ICE has allegedly over-discriminated certain racial groups.\n",
    "\n",
    "Previously, work regarding our research question has been done and public data sets exist that compile ICE arrest and deportation records.<a href=\"#ref1\">1</a> This dataset shows information, including race, on many people ICE has encountered, arrested, detained, transported, deported, and jailed. However, this dataset lacks information about the total amount of immigrants from each country, and just gives raw data about the amount of immigrants that were arrested, etc. from a given country. There has also been research done regarding ICE arrest statistics in major US cities and their different types of arrests. <a href=\"#ref2\">2</a> This source has data on the arrest date, arrest city, country of citizenship, and criminality. However, a drawback to this source is the lack of accessibility of more specific data. There is only broad statistics having to do with ICE arrests in major cities. Furthermore, there is information about individual encounters with ICE enforcement in the final source. <a href=\"#ref3\">3</a> This source gives much more individual detail than the other sources, but still is lacking in terms of real-time updates.\n",
    "\n",
    "Through analyzing data from these three sources, we can begin to answer how the distribution of ICE arrests by country of citizenship has shifted across 2023, 2024, and 2025, and whether certain countries have become more or less overrepresented over time. Specifically, our group is measuring arrests done by ICE per country of origin of immigrants in the United States. This will be represented by the number of immigrants from a given country that have been arrested divided by the total number of ICE cases in the from the respective year 2023, 2024 and 2025.\n",
    "\n",
    "<a name=\"ref1\"></a>\n",
    "**1.** ICE Arrests, Detention, and Deportation Data (Kaggle).  \n",
    "https://www.kaggle.com/datasets/bwandowando/ice-arrests-detention-and-deportation-data/data  \n",
    "[↩](#ref1)\n",
    "\n",
    "<a name=\"ref2\"></a>\n",
    "**2**. U.S. Immigration and Customs Enforcement. Immigration Enforcement Statistics.  \n",
    "https://www.ice.gov/statistics  \n",
    "[↩](#ref2)\n",
    "\n",
    "<a name=\"ref3\"></a>\n",
    "**3**. Deportation Data Project. DeportationData.org.  \n",
    "https://deportationdata.org/index.html  \n",
    "[↩](#ref3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that the distribution of ICE arrests by country of citizenship will shift noticeably from 2023 to 2025, with some countries making up a growing share of total arrests while others decline. Specifically we expect individuals from Latin American countries to remain consistently overrepresented across all three years, largely due to longstanding enforcement patterns that have historically targeted populations perceived as more likely to lack legal documentation. Furthermore, we expect this overrepresentation to grow over time, driven by the increasing aggressiveness of ICE enforcement in recent years."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets.\n",
    "\n",
    "#### U.S. ICE 2023-2025 Historical Data - Arrests Dataset\n",
    "\n",
    "https://www.kaggle.com/datasets/bwandowando/ice-arrests-detention-and-deportation-data/data\n",
    "\n",
    "\n",
    "#### U.S. ICE 2011-2023 Historical Data - Removal Dataset \n",
    "\n",
    "https://www.kaggle.com/datasets/bwandowando/ice-2012-2023-historical-data\n",
    "\n",
    "***2011-2023 arrests datset does not include country of citizenship so using this dataset and using coulumns apprehension date and countru of citizenship as a substitute***\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Download Progress:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Downloading ice_arrests_2023_2025.csv: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Overall Download Progress:  33%|███▎      | 1/3 [00:02<00:04,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: ice_arrests_2023_2025.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading ice_arrests_2011_2023.csv: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Overall Download Progress:  67%|██████▋   | 2/3 [00:03<00:01,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: ice_arrests_2011_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading ice_removals_2011_2023.csv: 0.00B [00:00, ?B/s]\u001b[A\n",
      "Overall Download Progress: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: ice_removals_2011_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://docs.google.com/spreadsheets/d/1cqg27xsYpE_Jb5UxPetbhs0oWp1sotqrwln-ByW__Ks/export?format=csv&gid=476095224', 'filename':'ice_arrests_2023_2025.csv'},\n",
    "    { 'url': 'https://docs.google.com/spreadsheets/d/1c1Hpfbf50uU3CX1S4G-XapzaDTKCIrR3Di3POziNVP4/export?format=csv&gid=678712776', 'filename':'ice_arrests_2011_2023.csv'},\n",
    "    { 'url': 'https://docs.google.com/spreadsheets/d/1NKVmsceNFCyc3zSGiAhPxky-ASkx1KCiH0_63FuLInA/export?format=csv&gid=347174332', 'filename':'ice_removals_2011_2023.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidying Data\n",
    "As you can see the above table belows is aleady tidy, each row is representing an individual observation and it is rectangular such that each variable measured is in a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apprehension_date</th>\n",
       "      <th>apprehension_state</th>\n",
       "      <th>apprehension_aor</th>\n",
       "      <th>final_program</th>\n",
       "      <th>final_program_group</th>\n",
       "      <th>apprehension_method</th>\n",
       "      <th>apprehension_criminality</th>\n",
       "      <th>case_status</th>\n",
       "      <th>case_category</th>\n",
       "      <th>departed_date</th>\n",
       "      <th>...</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>citizenship_country</th>\n",
       "      <th>gender</th>\n",
       "      <th>apprehension_site_landmark</th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>apprehension_date_time</th>\n",
       "      <th>duplicate_likely</th>\n",
       "      <th>file_original</th>\n",
       "      <th>sheet_original</th>\n",
       "      <th>row_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston Area of Responsibility</td>\n",
       "      <td>Law Enforcement Area Response Units</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1976</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/1/2023 18:53:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston Area of Responsibility</td>\n",
       "      <td>Law Enforcement Area Response Units</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1979</td>\n",
       "      <td>COLOMBIA</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/1/2023 18:53:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Paso Area of Responsibility</td>\n",
       "      <td>Non-Detained Docket Control</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1985</td>\n",
       "      <td>HAITI</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/1/2023 22:13:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El Paso Area of Responsibility</td>\n",
       "      <td>Non-Detained Docket Control</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1985</td>\n",
       "      <td>HAITI</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/1/2023 22:51:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/2/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston Area of Responsibility</td>\n",
       "      <td>Law Enforcement Area Response Units</td>\n",
       "      <td>ICE</td>\n",
       "      <td>Inspections</td>\n",
       "      <td>3 Other Immigration Violator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>PERU</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/2/2023 14:40:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx</td>\n",
       "      <td>Admin Arrests</td>\n",
       "      <td>371695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  apprehension_date apprehension_state                apprehension_aor  \\\n",
       "0          9/1/2023                NaN   Boston Area of Responsibility   \n",
       "1          9/1/2023                NaN   Boston Area of Responsibility   \n",
       "2          9/1/2023                NaN  El Paso Area of Responsibility   \n",
       "3          9/1/2023                NaN  El Paso Area of Responsibility   \n",
       "4          9/2/2023                NaN   Boston Area of Responsibility   \n",
       "\n",
       "                         final_program final_program_group  \\\n",
       "0  Law Enforcement Area Response Units                 ICE   \n",
       "1  Law Enforcement Area Response Units                 ICE   \n",
       "2          Non-Detained Docket Control                 ICE   \n",
       "3          Non-Detained Docket Control                 ICE   \n",
       "4  Law Enforcement Area Response Units                 ICE   \n",
       "\n",
       "  apprehension_method      apprehension_criminality  case_status  \\\n",
       "0         Inspections  3 Other Immigration Violator          NaN   \n",
       "1         Inspections  3 Other Immigration Violator          NaN   \n",
       "2         Inspections  3 Other Immigration Violator          NaN   \n",
       "3         Inspections  3 Other Immigration Violator          NaN   \n",
       "4         Inspections  3 Other Immigration Violator          NaN   \n",
       "\n",
       "   case_category  departed_date  ...  birth_year  citizenship_country  gender  \\\n",
       "0            NaN            NaN  ...        1976             COLOMBIA  Female   \n",
       "1            NaN            NaN  ...        1979             COLOMBIA    Male   \n",
       "2            NaN            NaN  ...        1985                HAITI    Male   \n",
       "3            NaN            NaN  ...        1985                HAITI    Male   \n",
       "4            NaN            NaN  ...        2008                 PERU  Female   \n",
       "\n",
       "   apprehension_site_landmark unique_identifier apprehension_date_time  \\\n",
       "0                         NaN               NaN      9/1/2023 18:53:32   \n",
       "1                         NaN               NaN      9/1/2023 18:53:34   \n",
       "2                         NaN               NaN      9/1/2023 22:13:54   \n",
       "3                         NaN               NaN      9/1/2023 22:51:03   \n",
       "4                         NaN               NaN      9/2/2023 14:40:53   \n",
       "\n",
       "   duplicate_likely                                      file_original  \\\n",
       "0               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "1               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "2               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "3               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "4               NaN  ERO Admin Arrests_LESA-STU-FINAL Release_raw.xlsx   \n",
       "\n",
       "  sheet_original  row_original  \n",
       "0  Admin Arrests        371689  \n",
       "1  Admin Arrests        371690  \n",
       "2  Admin Arrests        371691  \n",
       "3  Admin Arrests        371692  \n",
       "4  Admin Arrests        371695  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "import pandas as pd\n",
    "ice_arrests_2023_2025 = pd.read_csv(\"data/00-raw/ice_arrests_2023_2025.csv\")\n",
    "ice_arrests_2023_2025.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate that the data is tidy, we can inspect the unique values of some of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Female', 'Male'], dtype=object), array(['ICE'], dtype=object))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_arrests_2023_2025['gender'].unique(), ice_arrests_2023_2025['final_program_group'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the datset can also be dmeonstarted using the .shape feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_arrests_2023_2025.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows how many values are missing in the dataset, and from which columns, when totaled it comes out to 4474.The missingness does not appear to be random. The 500 missing values across case_status, case_category, departed_date and related columns likely correspond to the same rows, suggesting these records represent arrests where case outcomes have not yet been recorded. Similarly, the 234 missing values in unique_identifier and duplicate_likely appear to be systematically linked, possibly representing records that could not be matched to a unique case ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apprehension_date               0\n",
       "apprehension_state            499\n",
       "apprehension_aor                7\n",
       "final_program                   0\n",
       "final_program_group             0\n",
       "apprehension_method             0\n",
       "apprehension_criminality        0\n",
       "case_status                   500\n",
       "case_category                 500\n",
       "departed_date                 500\n",
       "departure_country             500\n",
       "final_order_yes_no            500\n",
       "final_order_date              500\n",
       "birth_year                      0\n",
       "citizenship_country             0\n",
       "gender                          0\n",
       "apprehension_site_landmark    500\n",
       "unique_identifier             234\n",
       "apprehension_date_time          0\n",
       "duplicate_likely              234\n",
       "file_original                   0\n",
       "sheet_original                  0\n",
       "row_original                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_arrests_2023_2025.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1 row with a recorded apprehension_state and the 7 rows missing apprehension_aor stand out as suspicious. Since apprehension_state is almost entirely absent across the dataset, the single non-missing entry is anomalous. Similarly, while apprehension_aor is largely complete, the 7 missing entries are unexpected for a geographic field that should be recorded for every arrest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Data\n",
    "To address missingness in the dataset, we dropped all columns except apprehension_date, citizenship_country, and unique_identifier, as these are the only columns relevant to our research question about the distribution of ICE arrests by country of citizenship. Since we are only measuring arrest counts by country and year, columns related to case outcomes, departure, and geographic processing are unnecessary for our analysis. Although unique_identifier contains some missing values, we retain it solely as an index to distinguish individual arrest cases rather than as a variable in our calculations, so its missingness does not affect our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apprehension_date</th>\n",
       "      <th>citizenship_country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>COLOMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>COLOMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>HAITI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>9/1/2023</td>\n",
       "      <td>HAITI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>9/2/2023</td>\n",
       "      <td>PERU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1/16/2024</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c576002685e70f3eee7cba69018e9d2fe06a232b</th>\n",
       "      <td>1/16/2024</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096dedc24c8d4f4dbc23d11fb4056d92be667f5</th>\n",
       "      <td>1/16/2024</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1/16/2024</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1/16/2024</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         apprehension_date citizenship_country\n",
       "unique_identifier                                                             \n",
       "NaN                                               9/1/2023            COLOMBIA\n",
       "NaN                                               9/1/2023            COLOMBIA\n",
       "NaN                                               9/1/2023               HAITI\n",
       "NaN                                               9/1/2023               HAITI\n",
       "NaN                                               9/2/2023                PERU\n",
       "...                                                    ...                 ...\n",
       "NaN                                              1/16/2024              MEXICO\n",
       "c576002685e70f3eee7cba69018e9d2fe06a232b         1/16/2024              MEXICO\n",
       "9096dedc24c8d4f4dbc23d11fb4056d92be667f5         1/16/2024              MEXICO\n",
       "NaN                                              1/16/2024              MEXICO\n",
       "NaN                                              1/16/2024              MEXICO\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_arrests_2023_2025_clean = ice_arrests_2023_2025[['apprehension_date', 'citizenship_country', 'unique_identifier']]\n",
    "ice_arrests_2023_2025_clean = ice_arrests_2023_2025_clean.set_index('unique_identifier')\n",
    "ice_arrests_2023_2025_clean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 U.S. ICE 2011–2023 Historical Removals Data\n",
    "\n",
    "<!-- See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the above table below is already tidy, each row is representing an individual observation and it is rectangular such that each variable measured is in a single column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2A: Data Description and Core Variables \n",
    "\n",
    "This dataset contains individual-level ICE removal records spanning 2011 through 2023. Each row represents a single removal case, and each column corresponds to an administrative attribute of that enforcement action. For the purposes of our analysis, we focus specifically on two core variables: Apprehension Date and Country of Citizenship, which allow us to construct annual distributions of removals by nationality.\n",
    "\n",
    "Key Metrics:\n",
    "\n",
    "1. Apprehension Date (date/timestamp format):\n",
    "This variable records the date on which the enforcement action was recorded. The unit of measurement is calendar time at the day level. For analytical purposes, we extract the year from this variable to aggregate removals by calendar year and enable longitudinal comparisons across 2011–2023.\n",
    "\n",
    "2. Country of Citizenship (categorical variable):\n",
    "This variable identifies the nationality of the individual removed. It is central to our research question, as we calculate the proportion of total removals attributable to each country in a given year.\n",
    "\n",
    "3. Removal Count (derived metric):\n",
    "Although the dataset does not explicitly provide aggregate totals, each row represents one removal event. Therefore, the count of rows corresponds to the total number of removals. These counts are obtained through grouping operations and are subsequently converted into proportions (measured as shares or percentages of total annual removals).\n",
    "\n",
    "Primary Outcome of Interest: is the proportional composition of removals by country within each year.\n",
    "\n",
    "Because overall enforcement volume fluctuates across years, we focus on proportions rather than raw counts. For example, if 30% of removals in a given year involve individuals from a specific country, this indicates that nearly one-third of enforcement outcomes that year were associated with that nationality. This proportional approach allows us to compare enforcement composition over time even when total removals increase or decrease.\n",
    "\n",
    "2B: Data Limitations and Methodological Considerations\n",
    "\n",
    "There are several important concerns to acknowledge.\n",
    "\n",
    "1. Structural incompatibility with arrest data:\n",
    "The 2011 arrest records cannot be reliably joined with the 2011 removal records due to differences in identifiers and data structure. To avoid introducing matching errors, we rely exclusively on the removals dataset for the 2011–2023 historical period.\n",
    "\n",
    "2. Policy-driven variation:\n",
    "ICE enforcement priorities shifted across administrations between 2011 and 2023. As a result, observed changes in removal proportions may reflect policy changes rather than underlying migration flows.\n",
    "\n",
    "3. Administrative data bias:\n",
    "This dataset captures enforcement outcomes, not the total undocumented population. It measures government enforcement activity rather than population-level prevalence.\n",
    "\n",
    "4. Missing administrative identifiers:\n",
    "Some internal identifiers contain missing values. However, because our analysis depends primarily on apprehension date and country of citizenship, this missingness does not materially affect our proportional calculations.\n",
    "\n",
    "5. Scope limitation:\n",
    "The dataset includes only individuals who were formally removed. It excludes those apprehended but released, voluntarily departed, or never encountered by enforcement authorities. Therefore, the data reflect enforcement outcomes rather than the broader undocumented population. Findings should be interpreted as changes in enforcement composition rather than changes in total immigrant presence.\n",
    "\n",
    "Relationship to Dataset #1\n",
    "\n",
    "Dataset #2 provides the historical baseline (2011–2023), while Dataset #1 extends the timeline into 2023–2025. To construct a continuous time series, we harmonize the shared variables (apprehension date and country of citizenship) and append the relevant 2023 records from Dataset #2 to Dataset #1. This produces a unified dataset spanning 2011–2025 for proportional analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apprehension Date</th>\n",
       "      <th>Apprehension Method</th>\n",
       "      <th>Arrest Created By</th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Alien File Number</th>\n",
       "      <th>Anonymized Identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/2011</td>\n",
       "      <td>287(g) Program</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>b32a39a8048b11c971b9f2caea46330d08a5fdbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/2011</td>\n",
       "      <td>287(g) Program</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>92d0efee458e60b9422f169533d3ff0c1ef12469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/1/2011</td>\n",
       "      <td>287(g) Program</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>85cb49e4d7b038e1e40afa410659b0db54b0aa42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/2011</td>\n",
       "      <td>287(g) Program</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>b02c9b812f277ee83af78b5fc6d177836c431108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/2/2011</td>\n",
       "      <td>287(g) Program</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>(b)(6)(b)(7)(c)</td>\n",
       "      <td>2e4d69e4ae7b08e87e263641eef563074714c5ce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Apprehension Date Apprehension Method Arrest Created By          Case ID  \\\n",
       "0         10/1/2011      287(g) Program   (b)(6)(b)(7)(c)  (b)(6)(b)(7)(c)   \n",
       "1         10/1/2011      287(g) Program   (b)(6)(b)(7)(c)  (b)(6)(b)(7)(c)   \n",
       "2         10/1/2011      287(g) Program   (b)(6)(b)(7)(c)  (b)(6)(b)(7)(c)   \n",
       "3         10/1/2011      287(g) Program   (b)(6)(b)(7)(c)  (b)(6)(b)(7)(c)   \n",
       "4         10/2/2011      287(g) Program   (b)(6)(b)(7)(c)              NaN   \n",
       "\n",
       "        Subject ID Alien File Number                     Anonymized Identifier  \n",
       "0  (b)(6)(b)(7)(c)   (b)(6)(b)(7)(c)  b32a39a8048b11c971b9f2caea46330d08a5fdbd  \n",
       "1  (b)(6)(b)(7)(c)   (b)(6)(b)(7)(c)  92d0efee458e60b9422f169533d3ff0c1ef12469  \n",
       "2  (b)(6)(b)(7)(c)   (b)(6)(b)(7)(c)  85cb49e4d7b038e1e40afa410659b0db54b0aa42  \n",
       "3  (b)(6)(b)(7)(c)   (b)(6)(b)(7)(c)  b02c9b812f277ee83af78b5fc6d177836c431108  \n",
       "4  (b)(6)(b)(7)(c)   (b)(6)(b)(7)(c)  2e4d69e4ae7b08e87e263641eef563074714c5ce  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "ice_arrests_2011_2023 = pd.read_csv(\"data/00-raw/ice_arrests_2011_2023.csv\")\n",
    "ice_arrests_2011_2023.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate that the data is tidy, we can inspect the unique values of some of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprehension Method values: ['287(g) Program']\n",
      "Arrest Created By values: ['(b)(6)(b)(7)(c)']\n"
     ]
    }
   ],
   "source": [
    "print('Apprehension Method values:', ice_arrests_2011_2023['Apprehension Method'].unique())\n",
    "print('Arrest Created By values:', ice_arrests_2011_2023['Arrest Created By'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the datset can also be dmeonstarted using the .shape feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apprehension Date         0\n",
       "Apprehension Method       0\n",
       "Arrest Created By         0\n",
       "Case ID                  22\n",
       "Subject ID                0\n",
       "Alien File Number         8\n",
       "Anonymized Identifier     8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_arrests_2011_2023.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5/17/2013 14:00:00\n",
       "1                      NaN\n",
       "2                      NaN\n",
       "3       7/15/2011 22:00:00\n",
       "4                      NaN\n",
       "              ...         \n",
       "495      10/1/2014 2:39:00\n",
       "496     11/14/2014 6:45:00\n",
       "497    11/22/2014 18:00:00\n",
       "498     12/10/2014 0:48:00\n",
       "499    12/15/2014 16:47:16\n",
       "Name: Apprehension Date, Length: 500, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_removals_2011_2023 = pd.read_csv(\"data/00-raw/ice_removals_2011_2023.csv\")\n",
    "ice_removals_2011_2023['Apprehension Date']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent? --> crucial\n",
    "\n",
    ">  We have publicly administered data from ICE and Keggle websites, we are not collecting information for human subjects throughout our project. Our data consist of information we gather from enforcement statistics instead of individual participants. \n",
    " \n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> We have considered that the data we are using specifically from the ICE website would reflect what they specifically chose to focus on and on certain policies that have changed. We are aware that the data would be based on ICE enforcement instead of the people themselves.  \n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> Our data set does not include any names or personal information on individuals, we are not trying to figure out who they are. \n",
    "    \n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> We are aware that Immigration is a heavy topic especially in the state of the world we are in right now, we will be careful to present the results of our data in a respectful way that doesnt shift blame or target certain groups. Making sure we focus on certain enforcement patterns instead of the individuals. \n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> The data we are using is public and does not include any personal information of individuals. Our data would be safely secured in datahub and github for this project.\n",
    "       \n",
    " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "> We are using that dataset only for this project, once the project is over the data will stay in our data repository just for documentation. \n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> We are aware that the dataset shows government reported data and patterns, and will most likely not include personal experience or certain perspectives of the individuals.  \n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> The data we have considered that it might have missing data or uneven reportings across different countries, since the data reflects enforcement activity instead of certain behaviors conducted. We will avoid making causal claims and just observing the patterns we see within the data.  \n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> We will make sure to make graphs and summaries that accurately represent the data we used, avoiding any skewed data.\n",
    " \n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> We will ensure that we will not display or use any personal information for our analysis.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "> Our analysis and data will be well documented in order for others to understand our work and if they decide they would be able to reproduce it clearly. \n",
    "\n",
    "### D. Modeling\n",
    " - [ ] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "> Our data shows arrest, removals, etc. But it does not explain specific reasons behind these actions and we also don't know the experiences of the people affected by this. With that being said we will make sure to make that a point when presenting our results, making the limits clear. \n",
    "\n",
    "### E. Deployment\n",
    " - [ ] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    " - [ ] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [ ] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "> We are aware that some of the data and findings that we use could be mistaken to support harmful narratives. So we will make it clear in our analysis to explain everything to reduce potential risks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our COGS 108 project examining whether ICE arrest activity has differed by country of citizenship over the last two years (2023 - 2025), we agree to work as a collaborative, respectful, and accountable team. Given the sensitivity of immigration-related data and the interdisciplinary nature of this topic, we recognize the importance of clear communication, shared responsibility, and mutual respect throughout the quarter.\n",
    "\n",
    "Communication \n",
    "We will primarily communicate through Messenger with the expectation that messages will be acknowledged within 24 hours. We will schedule weekly meetings (remote, as agreed upon) to review progress, assign tasks and discuss challenges. If a team member anticipates being unavailable or delayed, they will notify the group as soon as possible.\n",
    "\n",
    "Tone and Respect\n",
    "We commit to maintaining a professional, respectful, and constructive tone in all interactions. We agree to be honest and direct while remaining polite. Given that this project involves topics related to immigration and enforcement, we will be especially mindful to discuss findings analytically and respectfully, separating personal opinions from data-driven conclusions.\n",
    "\n",
    "Decision-Making\n",
    "Whenever possible, decisions will be made by consensus. If consensus cannot be reached in a reasonable timeframe, we will use a majority vote. For time-sensitive decisions (e.g., minor coding or formatting choices), the team member responsible for that section may proceed and update the group afterward.\n",
    "\n",
    "Task Distribution and Accountability\n",
    "Work will be divided equitably based on individual strengths (e.g., data wrangling, analysis, visualization, writing), while ensuring that every member contributes to all major aspects of the project: data selection, analysis, code development, interpretation, and writing. Tasks and deadlines will be tracked using a shared task board or document (e.g., GitHub Issues, Google Docs). No single team member is expected to carry a disproportionate share of the workload.\n",
    "\n",
    "Supporting One Another\n",
    "If a team member is struggling with an assigned task, they are expected to communicate this early so the team can redistribute work or provide support. We agree to approach these situations with understanding and problem-solving rather than blame.\n",
    "\n",
    "Conflict Resolution\n",
    "If conflicts arise, we will address them directly, respectfully, and privately as a group before escalating. We will assume good intentions and focus on resolving issues in a way that supports both the project’s success and the well-being of the team. If serious issues persist, we understand that reaching out to course staff is an appropriate step, in line with course policy.\n",
    "\n",
    "Commitment\n",
    "By adding our names to this submission, we confirm that we have read the COGS108 Team Policies, agree to the expectations outlined above, and are committed to contributing fully and responsibly to this project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: Replace this with your timeline.  **PLEASE UPDATE your Timeline!** No battle plan survives contact with the enemy, so make sure we understand how your plans have changed.  Also if you have lost points on the previous checkpoint fix them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
